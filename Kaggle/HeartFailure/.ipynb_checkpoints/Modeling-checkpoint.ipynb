{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d32d875",
   "metadata": {},
   "source": [
    "# Heart Failure Prediction\n",
    "\n",
    "**Reference**\n",
    "- [Heart Fail:Analysis and Quick-prediction (NAYAN SAKHIYA)](https://www.kaggle.com/code/nayansakhiya/heart-fail-analysis-and-quick-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "9b66b2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d8ebc",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "b566182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.192945</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>1</td>\n",
       "      <td>1.681648e-02</td>\n",
       "      <td>0.490057</td>\n",
       "      <td>-1.504036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.629502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.491279</td>\n",
       "      <td>0</td>\n",
       "      <td>7.514640</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>0</td>\n",
       "      <td>7.535660e-09</td>\n",
       "      <td>-0.284552</td>\n",
       "      <td>-0.141976</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.603691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.350833</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.449939</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.038073e+00</td>\n",
       "      <td>-0.090900</td>\n",
       "      <td>-1.731046</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.590785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.912335</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.486071</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.464741e-01</td>\n",
       "      <td>0.490057</td>\n",
       "      <td>0.085034</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.590785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.350833</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.435486</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>0</td>\n",
       "      <td>6.517986e-01</td>\n",
       "      <td>1.264666</td>\n",
       "      <td>-4.682176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.577879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.456114</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.552141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162199</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.079240e-01</td>\n",
       "      <td>0.683709</td>\n",
       "      <td>-1.050016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.577879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.192945</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.346704</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.953749</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.396531e+00</td>\n",
       "      <td>-0.187726</td>\n",
       "      <td>0.085034</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.552067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.070223</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.275472</td>\n",
       "      <td>1</td>\n",
       "      <td>1.854958</td>\n",
       "      <td>0</td>\n",
       "      <td>1.952488e+00</td>\n",
       "      <td>-0.284552</td>\n",
       "      <td>-1.277026</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.552067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.350833</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.438583</td>\n",
       "      <td>0</td>\n",
       "      <td>2.278147</td>\n",
       "      <td>0</td>\n",
       "      <td>7.535660e-09</td>\n",
       "      <td>0.102752</td>\n",
       "      <td>0.312044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.552067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.614001</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.473683</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.260991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.276539e+00</td>\n",
       "      <td>7.752020</td>\n",
       "      <td>-0.823006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.552067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  1.192945        0                  0.000166         0          -1.530560   \n",
       "1 -0.491279        0                  7.514640         0          -0.007077   \n",
       "2  0.350833        0                 -0.449939         0          -1.530560   \n",
       "3 -0.912335        1                 -0.486071         0          -1.530560   \n",
       "4  0.350833        1                 -0.435486         1          -1.530560   \n",
       "5  2.456114        1                 -0.552141         0           0.162199   \n",
       "6  1.192945        1                 -0.346704         0          -1.953749   \n",
       "7 -0.070223        1                 -0.275472         1           1.854958   \n",
       "8  0.350833        0                 -0.438583         0           2.278147   \n",
       "9  1.614001        1                 -0.473683         0          -0.260991   \n",
       "\n",
       "   high_blood_pressure     platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  1.681648e-02          0.490057     -1.504036    1   \n",
       "1                    0  7.535660e-09         -0.284552     -0.141976    1   \n",
       "2                    0 -1.038073e+00         -0.090900     -1.731046    1   \n",
       "3                    0 -5.464741e-01          0.490057      0.085034    1   \n",
       "4                    0  6.517986e-01          1.264666     -4.682176    0   \n",
       "5                    1 -6.079240e-01          0.683709     -1.050016    1   \n",
       "6                    0 -1.396531e+00         -0.187726      0.085034    1   \n",
       "7                    0  1.952488e+00         -0.284552     -1.277026    1   \n",
       "8                    0  7.535660e-09          0.102752      0.312044    0   \n",
       "9                    1  1.276539e+00          7.752020     -0.823006    1   \n",
       "\n",
       "   smoking      time  \n",
       "0        0 -1.629502  \n",
       "1        0 -1.603691  \n",
       "2        1 -1.590785  \n",
       "3        0 -1.590785  \n",
       "4        0 -1.577879  \n",
       "5        1 -1.577879  \n",
       "6        0 -1.552067  \n",
       "7        1 -1.552067  \n",
       "8        0 -1.552067  \n",
       "9        1 -1.552067  "
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('./heart_failure_clinical_records_dataset.csv')\n",
    "#df = df.drop(df.loc[df['creatinine_phosphokinase']>3000].index, axis=0)\n",
    "# df = pd.get_dummies(df)\n",
    "\n",
    "float_columns = [x for x in df.columns if x not in ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT']]\n",
    "sc = StandardScaler()\n",
    "df2 = df.copy()\n",
    "df[float_columns] = sc.fit_transform(df[float_columns])\n",
    "\n",
    "#df.to_csv('Heart_Failure_scaled.csv', encoding='utf-8-sig')\n",
    "\n",
    "X = df.drop(['DEATH_EVENT'], axis=1)\n",
    "T = df['DEATH_EVENT']\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fca00a",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "dc6fcd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age  ejection_fraction  serum_creatinine\n",
      "0    1.192945          -1.530560          0.490057\n",
      "1   -0.491279          -0.007077         -0.284552\n",
      "2    0.350833          -1.530560         -0.090900\n",
      "3   -0.912335          -1.530560          0.490057\n",
      "4    0.350833          -1.530560          1.264666\n",
      "..        ...                ...               ...\n",
      "294  0.098199          -0.007077         -0.284552\n",
      "295 -0.491279          -0.007077         -0.187726\n",
      "296 -1.333392           1.854958         -0.575031\n",
      "297 -1.333392          -0.007077          0.005926\n",
      "298 -0.912335           0.585389          0.199578\n",
      "\n",
      "[299 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Features = ['age', 'ejection_fraction', 'serum_creatinine']\n",
    "X = df[Features]\n",
    "print(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, T, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79aea80",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "1fe22459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from colorama import Fore\n",
    "\n",
    "accuracy_list=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e2777",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "7d2e7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3912ed71",
   "metadata": {},
   "source": [
    "### Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "783d7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a7ded",
   "metadata": {},
   "source": [
    "### K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "f804392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebded7b",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "75ebd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23345058",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "2637fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ba8a8",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "c1b15044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a529664a",
   "metadata": {},
   "source": [
    "### XGBRF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "cc15c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af5b88",
   "metadata": {},
   "source": [
    "### LGBM Classifier\n",
    "\n",
    "\n",
    "[**Reference...**](https://nurilee.com/2020/04/03/lightgbm-definition-parameter-tuning/)\n",
    "- **Gradient Boosting Framework**\n",
    "- ML Algorithm based on **Tree Model**\n",
    "    - Light GBM: **Tree가 수직적으로 확장**\n",
    "        - Leaf-wise 방식\n",
    "        <img src=\"./Leaf_wise_tree_growth.png\" width=\"500px\" height=\"400px\" title=\"Leaf_wise\"></img>\n",
    "    - Others: **Tree가 수평적으로 확장**\n",
    "        - Level-wise 방식\n",
    "        <img src=\"./Level_wise_tree_growth.png\" width=\"400px\" height=\"250px\" title=\"Level_wise\"></img>\n",
    "\n",
    "- **Light GBM이 인기를 얻게된 이유**\n",
    "    - 속도가 빠름\n",
    "    - 큰 사이즈의 데이터를 다룰 수 있으며 적은 메모리 공간을 차지\n",
    "    - 정확도가 높음\n",
    "    - GPU gkrtmqdmf wldnjs\n",
    "- **Light GBM 사용처**\n",
    "    - 작은 데이터셋에는 부적합\n",
    "    - Overfitting에 민감\n",
    "    - row size에 대한 제한은 없으나 10,000개 이상에 권장\n",
    "- **Light GBM 구현**\n",
    "    - Parameter tuning이 복잡 (100개 이상)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07733350",
   "metadata": {},
   "source": [
    "**Parameters**  \n",
    "- `max_depth`: \n",
    "    - Tree의 최대 깊이. 과적합을 해결할 때 사용\n",
    "- `min_data_in_leaf`: \n",
    "    - Leaf가 가지고 있는 최소한의 레코드 수\n",
    "    - 과적합을 해결할 때 사용\n",
    "    - 큰 값으로 세팅함으로써 Tree가 너무 깊게 확장되는 것을 방지할 수 있음\n",
    "        - 하지만 underfitting이 발생할 수 있음\n",
    "    - 관행적으로 수백~수천 개로 정하는 것이 큰 데이터셋에서 충분\n",
    "    - *default value 20\n",
    "- `feature_fraction`:\n",
    "    - Boosting이 Random Forest일 경우 사용\n",
    "    - 0.8 feature_fraction\n",
    "        - Light GBMdl Tree를 만들 때 매번 각각의 iteration 반복에서 파라미터 중에 80%를 랜덤하게 선택\n",
    "- `bagging_fraction`:\n",
    "    - 매번 iteration을 돌 때 사용되는 데이터의 일부를 선택하는데 트레이닝 속도를 높이고 과적합을 방지할 때 주로 사용\n",
    "- `early_stopping_round`:\n",
    "    - 분석 속도를 높이는데 도움을 줌\n",
    "    - 모델은 만약 어떤 validation 데이터 중 하나의 지표가 지난 early_stopping_round 라운드에서 향상되지 않았다면 학습을 중단함\n",
    "        - 이는 지나친 iteration을 줄이는데 도움을 줌\n",
    "- `lambda`:\n",
    "    - lambda값은 regularization 정규화를 함\n",
    "    - 0~1 사이\n",
    "- `min_gain_to_split`:\n",
    "    - 분기하기 위해 필요한 최소한의 gain을 의미\n",
    "    - Tree의 유용한 분기수를 컨트롤하는데 사용\n",
    "- `max_cat_group`:\n",
    "    - 카테고리 수가 클 때, 과적합을 방지하는 분기포인트를 찾음\n",
    "    - Light GBM 알고리즘이 카테고리 그룹을 max_cat_group 그룹으로 합치고 그룹 경계선에서 분기 포인트를 찾음\n",
    "    - *default value 64\n",
    "\n",
    "**Core Parameters**\n",
    "- `Task`:\n",
    "    - 데이터에 대해서 수행하고자 하는 임무를 구체화\n",
    "    - training or prediction\n",
    "- `application`:\n",
    "    - 가장 중요한 파라미터로, 모델의 어플리케이션을 정함\n",
    "    - regression or classification\n",
    "    - dafault value $\\text{regression}$\n",
    "        - regression: 회귀분석\n",
    "        - binary: 이진 분류\n",
    "        - multiclass: 다중 분류\n",
    "- `boosting`:\n",
    "    - 실행하고자 하는 알고리즘 타입을 정의\n",
    "    - default value $\\text{gdbt}$\n",
    "        - gdbt: Traditional Gradient Boosting Decision Tree\n",
    "        - rf: Random Forest\n",
    "        - dart: Dropouts meet Multiple Additive Regression Trees\n",
    "        - goss: Gradient-based One-Side Sampling\n",
    "- `num_boost_round`:\n",
    "    - boosting iteration 수로 일반적으로 100 이상\n",
    "- `learning_rate`:\n",
    "    - 최종 결과에 대한 각각의 Tree에 영향을 미치는 변수\n",
    "    - GBM은 초기 수정값에서 시작하여 각각의 Tree 결과를 사용하여 추정값을 업데이트\n",
    "    - 학습 파라미터는 이러한 추정에서 발생하는 변화의 크기를 컨트롤\n",
    "    - 일반적인 값으로 0.1, 0.001, 0.003 등이 있음\n",
    "- `num_leaves`:\n",
    "    - Tree 모델의 복잡성을 컨트롤하는 주요 파라미터\n",
    "    - 전체 Tree의 leaves 수를 나타냄\n",
    "    - 이상적으로 num_leaves 값은 2**(max_depth)값보다 적거나 같아야 함\n",
    "        - 이 것보다 많으면 과적합 유발\n",
    "    - default value 31\n",
    "- `device`:\n",
    "    - default value $\\text{cpu}$\n",
    "\n",
    "**Metric Parameter**\n",
    "- `metric`:\n",
    "    - 모델을 구현할 때 손실을 정리하기 때문에 중요한 변수 중 하나\n",
    "    - regression과 classification을 위한 일반적인 손실 값으로\n",
    "        - mae: mean absolute error\n",
    "        - mse: mean squared error\n",
    "        - binary_logloss: loss for binary classification\n",
    "        - multi_logloss: loss for multi classification\n",
    "\n",
    "**IO Parameter**\n",
    "- `max_bin`:\n",
    "    - feature 값의 최대 bin 수를 의미  \n",
    "- `categorical_features`:\n",
    "    - 범주형 feature 인덱스를 의미\n",
    "    - categorical_features가 0,1,2 이면 column 0, column 1, column 2가 범주형 변수들\n",
    "- `ignore_column`:\n",
    "    - categorical_features와 거의 동일\n",
    "    - feature로써 특정 칼럼을 고려하지 않음 (해당 변수들을 무시)\n",
    "- `save_binary`:\n",
    "    - 데이터 파일의 메모리 사이즈를 처리해야한다면 해당 파라미터를 True로 설정\n",
    "    - 해당 값이 True일 때, 데이터 세트는 바이너리 파일로 저장\n",
    "    - 이 바이너리 파일은 다음에 데이터를 읽어올 때 그 속도를 줄여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d492163",
   "metadata": {},
   "source": [
    "**더 빠른 속도**\n",
    "- `bagging_fraction` & `baggin_freq`를 설정하여 bagging을 적용\n",
    "- `feature_fraction`을 설정하여 feature sub-sampling을 시도\n",
    "- 작은 `max_bin` 값 적용\n",
    "- `save_binary`를 통해 향후 학습에서 데이터 로딩 속도를 감소\n",
    "- parallel learning 시도\n",
    "\n",
    "**더 높은 정확도**\n",
    "- 큰 `max_bin` 값 적용\n",
    "- 작은 `learning_rate`값을 큰 `num_iterations`값과 함께 적용\n",
    "- 큰 `num_leaves`값을 사용 (과적합을 유발)\n",
    "- 더 큰 traing data 사용\n",
    "- dart 사용\n",
    "- categorical feature 사용\n",
    "\n",
    "**과적합 해결**\n",
    "- 작은 `max_bin` 값 사용\n",
    "- 작은 `num_leaves` 값을 사용\n",
    "- `min_data_in_leaf`와 `min_sum_hessian_in_leaf` 파라미터를 사용\n",
    "- `bagging_fraction`과 `bagging_freq`를 사용하여 bagging을 적용\n",
    "- `feature_fraction`을 설정하여 feature sub-sampling을 시도\n",
    "- lambda_l1, lambda_l2 그리고 `min_gain_to_split` 파라미터를 이용해 regularization을 적용\n",
    "- `max_depth`를 설정해서 Deep Tree가 만들어지는 것을 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "6f06ac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy of LGBM Classifier is : 73.33%\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(max_depth=2,random_state=4)\n",
    "lgb_clf.fit(x_train, y_train)\n",
    "lgb_pred = lgb_clf.predict(x_test)\n",
    "lgb_acc = accuracy_score(y_test, lgb_pred)\n",
    "accuracy_list.append(100*lgb_acc)\n",
    "print(Fore.GREEN + f'Accuracy of LGBM Classifier is : {100*lgb_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "472a4518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 79, number of negative: 160\n",
      "[LightGBM] [Info] Total Bins 67\n",
      "[LightGBM] [Info] Number of data points in the train set: 239, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.330544 -> initscore=-0.705726\n",
      "[LightGBM] [Info] Start training from score -0.705726\n"
     ]
    }
   ],
   "source": [
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "params={}\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['num_leaves'] = 2\n",
    "params['max_depth'] = 2\n",
    "#params['max_bin'] = 1000\n",
    "params['learning_rate'] = 0.1\n",
    "params['force_row_wise']=True\n",
    "params['objective'] = 'binary'\n",
    "\n",
    "lgb_clf2 = lgb.train(params, d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "54b9131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy of LGBM Classifier is : 83.33%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lgb_pred2 = lgb_clf2.predict(x_test)\n",
    "preds_ld = lgb_pred2.flatten()\n",
    "pred_class = np.where(preds_ld >=0.5, 1, 0)\n",
    "lgb_acc2 = accuracy_score(y_test, pred_class)\n",
    "print(Fore.GREEN + f'Accuracy of LGBM Classifier is : {100*lgb_acc2:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00fd308",
   "metadata": {},
   "source": [
    "### Cat Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "5c152c8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [467]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055638b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
